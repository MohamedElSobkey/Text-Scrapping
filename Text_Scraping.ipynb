{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "BxhJxI7IULXX",
        "lJB_0CS4Y92S",
        "EG03pADrdhQ1",
        "2le86aVld7Zj",
        "ZRv1oUaDeqeQ",
        "Fzr2MfPah0ai"
      ],
      "authorship_tag": "ABX9TyOLhF5hnJpBACbohMN9mfHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedElSobkey/Text-Scrapping/blob/main/Text_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requests"
      ],
      "metadata": {
        "id": "BxhJxI7IULXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK1T-qEjG3dL"
      },
      "outputs": [],
      "source": [
        "import requests # get data with its rubbish\n",
        "content = requests.get(\"https://www.gutenberg.org/files/11/11-0.txt\") # get content\n",
        "type(content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content.text"
      ],
      "metadata": {
        "id": "6t3MyeaXR-sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(content.text.split())"
      ],
      "metadata": {
        "id": "_halOYkzSDWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"6.2.1 wonderland.txt\", \"w\", encoding=\"utf-8\")\n",
        "f.write(content.text) # save a file\n",
        "f.close()"
      ],
      "metadata": {
        "id": "4O2J1jo-SGfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DownloadText(Link,FileName) :\n",
        "    content = requests.get(Link)\n",
        "    print(content.text[:100])\n",
        "    f = open(FileName, \"w\", encoding=\"utf-8\")\n",
        "    f.write(content.text)\n",
        "    f.close()\n",
        "\n",
        "DownloadText(\"http://www.gutenberg.org/cache/epub/11/pg11.txt\",'alice.txt')"
      ],
      "metadata": {
        "id": "eAlNclMOSwE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests,re"
      ],
      "metadata": {
        "id": "-IW4xNF1UCIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = requests.get(r'https://ar.wikipedia.org/wiki/%D8%A3%D8%AF%D9%88%D9%84%D9%81_%D9%87%D8%AA%D9%84%D8%B1')\n",
        "Text = page.text\n",
        "Text = re.sub(r'[0-9A-Za-z<>!+=+\"\\n:,.\\]\\[\\\\\\/\\t()$%^&{}?;@#|_-]', '', Text) # delete anything not important\n",
        "Text"
      ],
      "metadata": {
        "id": "RZxy_DEsVQcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetPage(Word) :\n",
        "    page = requests.get(r'https://ar.wikipedia.org/wiki/'+Word)\n",
        "    Text = page.text\n",
        "    Text = re.sub(r'[0-9A-Za-zä%“”úáíóííóíé<>!+=+\"\\n:,.\\]\\[\\\\\\/\\t()$%^&{}?;@#|_-]', '', Text)\n",
        "    return Text[:10000]"
      ],
      "metadata": {
        "id": "Ko59aOPRVbx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GetPage('الصومال')"
      ],
      "metadata": {
        "id": "M5wS6TuTYNGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GetPage('الحرب العالمية الثانية')"
      ],
      "metadata": {
        "id": "7RpyUY1OYo1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = requests.get(r'http://agri-db.org/ar/agri-inputs/capro-g')\n",
        "Text = page.text\n",
        "Text = re.sub(r'[0-9A-Za-zä%“”úáíóííóíé<>!+=+\"\\n:,.\\]\\[\\\\\\/\\t()$%^&{}?;@#|_-]', '', Text)\n",
        "Text"
      ],
      "metadata": {
        "id": "nVv-HkpHYtnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BS"
      ],
      "metadata": {
        "id": "lJB_0CS4Y92S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DownloadText(\"https://en.wikipedia.org/wiki/Albert_Einstein\",'Albert.txt')"
      ],
      "metadata": {
        "id": "d4ie8MD3Y44X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup # make a clean data\n",
        "import requests\n",
        "page = requests.get(\"https://en.wikipedia.org/wiki/Albert_Einstein\")\n",
        "page.text"
      ],
      "metadata": {
        "id": "8XG3K_MSZA_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "soup"
      ],
      "metadata": {
        "id": "of595rqAZFUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = soup.find(id=\"firstHeading\")\n",
        "print(title.string)"
      ],
      "metadata": {
        "id": "ZgvwBISeZJUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.find_all('p')[2].get_text()) # show the third paragraph"
      ],
      "metadata": {
        "id": "Dn4xdqoiZOkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetPage(Link,FileName) :\n",
        "    page = requests.get(Link)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    print(f'Number of paragraphs is :  {len(soup.find_all(\"p\"))}') # show all paragraphs\n",
        "    try :                    # to check if there is a firstHeading or not\n",
        "        title = soup.find(id=\"firstHeading\")\n",
        "        print(f'Page title is :   {title.string}')\n",
        "    except :\n",
        "        pass\n",
        "    if len(soup.find_all('p')) ==0 : return None  # if there in no paragraph get out\n",
        "    f = open(FileName,'w',encoding = 'utf-8')\n",
        "    for i in range(len(soup.find_all('p'))) :                  # make a saving for all paragraph in the file\n",
        "        f.write(soup.find_all('p')[i].get_text())\n",
        "        f.write('\\n')\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "f9MFvY40Zdqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GetPage('https://en.wikipedia.org/wiki/Albert_Einstein','BSAlbert.txt')"
      ],
      "metadata": {
        "id": "ljfH0Oyyaum8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GetPage('https://www.bbc.co.uk/news/world-latin-america-57750358','bbc3.txt')"
      ],
      "metadata": {
        "id": "Fj3Soopka5zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GetPage('https://www.aljazeera.net/midan/miscellaneous/science/2021/7/6/%D8%A7%D9%84%D8%B3%D8%B1-%D8%A7%D9%84%D8%A3%D9%83%D8%A8%D8%B1-%D9%84%D9%90%D9%85%D9%8E-%D9%86%D8%B4%D8%A3%D8%AA-%D8%A7%D9%84%D8%AD%D9%8A%D8%A7%D8%A9-%D8%B9%D9%84%D9%89-%D8%A7%D9%84%D8%A3%D8%B1%D8%B6','aljazeera.txt')"
      ],
      "metadata": {
        "id": "7WW4dDGma8o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GetPage('https://www.facebook.com/RBReich','RR.txt')"
      ],
      "metadata": {
        "id": "KOyGVwyYbAYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GetPage('https://www.facebook.com/RBReich/posts/4479905548688673','RR.txt')"
      ],
      "metadata": {
        "id": "6s5GPVxBbLRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# URL Lib"
      ],
      "metadata": {
        "id": "EG03pADrdhQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request"
      ],
      "metadata": {
        "id": "LGfuyAKzdc4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DownloadText(\"https://raw.githubusercontent.com/jangedoo/jange/master/dataset/bbc.csv\",'bbc.csv')"
      ],
      "metadata": {
        "id": "53G_SZEqdvOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/HeshamAsem/NLTK/master/Files/HardTimes.txt'\n",
        "response = urllib.request.urlopen(url)\n",
        "data = response.read().decode('utf8')\n",
        "data"
      ],
      "metadata": {
        "id": "uqY5fUlldyKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('HardTimes.txt','w')\n",
        "f.write(data)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "cWv5l0qDd1Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BBC"
      ],
      "metadata": {
        "id": "2le86aVld7Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = 'https://www.bbc.co.uk/news/election-us-2020-53898142'\n",
        "response = urllib.request.urlopen(url)\n",
        "response"
      ],
      "metadata": {
        "id": "iNapmy9td5Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = response.read().decode('utf8')\n",
        "len(data)"
      ],
      "metadata": {
        "id": "xabrBzGseDkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "EFKr-qGbeHkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table"
      ],
      "metadata": {
        "id": "ZRv1oUaDeqeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import re"
      ],
      "metadata": {
        "id": "TZC2MtP_eaf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Epidemiology_of_depression'\n",
        "html = urlopen(url)\n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ],
      "metadata": {
        "id": "5BFNGzBmg5X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup"
      ],
      "metadata": {
        "id": "eE9bT-NHhK9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables = soup.find_all('table')"
      ],
      "metadata": {
        "id": "7VFPGJ6JhNiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables"
      ],
      "metadata": {
        "id": "wwK-rmGAhP9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tables)"
      ],
      "metadata": {
        "id": "4kKuNOd4hVZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tables)"
      ],
      "metadata": {
        "id": "GsmCcyPShWRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_num(num):\n",
        "    return float(re.sub(r'[^\\w\\s.]','',num))\n",
        "num1 = float(re.sub(r'[^\\w\\s.]','','1,156.30'))\n"
      ],
      "metadata": {
        "id": "3E7F-ZyEhb8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num1"
      ],
      "metadata": {
        "id": "MpJ_4NyZheYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Value2017,Value1990,countries,AChAnge,RChAnge = [],[],[],[],[]\n",
        "for table in tables:\n",
        "    rows = table.find_all('tr')\n",
        "    for row in rows:\n",
        "        cells = row.find_all('td')\n",
        "        if len(cells) > 1:\n",
        "          try:\n",
        "            country = cells[0]\n",
        "            countries.append(country.text)\n",
        "            Value = cells[1]\n",
        "            Value1990.append(Value.text.strip())\n",
        "            Value = cells[2]\n",
        "            Value2017.append(process_num(Value.text.strip()))\n",
        "            Value = cells[3]\n",
        "            AChAnge.append(process_num(Value.text.strip()))\n",
        "            Value = cells[4]\n",
        "            RChAnge.append(process_num(Value.text.strip()))\n",
        "\n",
        "          except :\n",
        "            pass"
      ],
      "metadata": {
        "id": "ZsB6ZalphgrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame([[i.replace('\\n','') for i in countries],Value1990,Value2017,AChAnge,RChAnge],index = ['Country','1990','2017','AChAnge','RChAnge'] ).T\n",
        "data"
      ],
      "metadata": {
        "id": "NML4hXCQhlzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('ThisTable.csv')"
      ],
      "metadata": {
        "id": "OdRGCAuJhn_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Website"
      ],
      "metadata": {
        "id": "Fzr2MfPah0ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re,string,requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "r = requests.get('https://bola.kompas.com/')\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "link = []\n",
        "for i in soup.find('div', {'class':'most__wrap'}).find_all('a'):  # get the inside links\n",
        "    i['href'] = i['href'] + '?page=all'\n",
        "    link.append(i['href'])\n",
        "\n",
        "print(f'Number of links is ({len(link)})')\n",
        "print(f'second link is \\n')\n",
        "print(link[1])\n",
        "print('===============================')\n",
        "documents = []\n",
        "for i in link:\n",
        "    r = requests.get(i)\n",
        "    soup = BeautifulSoup(r.content, 'html.parser')\n",
        "    sen = []\n",
        "    for i in soup.find('div', {'class':'read__content'}).find_all('p'):\n",
        "        sen.append(i.text)\n",
        "    print(f'number of sentences is {len(sen)}')\n",
        "    documents.append(' '.join(sen))\n",
        "print('===============================')\n",
        "documents_clean = []\n",
        "for d in documents:\n",
        "    document_test = re.sub(r'[^\\x00-\\x7F]+', ' ', d)\n",
        "    document_test = re.sub(r'@\\w+', '', document_test)\n",
        "    document_test = document_test.lower()\n",
        "    document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)\n",
        "    document_test = re.sub(r'[0-9]', '', document_test)\n",
        "    document_test = re.sub(r'\\s{2,}', ' ', document_test)\n",
        "    documents_clean.append(document_test)\n",
        "\n",
        "print(documents_clean)\n"
      ],
      "metadata": {
        "id": "qC5ZXTOmh7wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen"
      ],
      "metadata": {
        "id": "rnHknrCjiecN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WebTeb"
      ],
      "metadata": {
        "id": "aN_Ywr0qtInZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T = 'دجحخهعغفقثصضذشسيبلاتنمكطظزوةىلارؤءئ' # جميع حروف اللغة العربية\n",
        "T = list(set(T))\n",
        "len(T)"
      ],
      "metadata": {
        "id": "IeXklQ8NtPvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(T) # To delete any repeatation"
      ],
      "metadata": {
        "id": "bLBFqFnDvS1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "urls = []\n",
        "for t in T :\n",
        "    url = r'https://www.webteb.com/drug/list/' + t\n",
        "    reqs = requests.get(url)\n",
        "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        "\n",
        "\n",
        "    for link in soup.find_all('a'):\n",
        "        urls.append(link.get('href'))\n",
        "urls"
      ],
      "metadata": {
        "id": "QdPDt2tZvddX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(urls)"
      ],
      "metadata": {
        "id": "XMNgxC9UxMQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U = [i for i in urls if 'https://www.webteb.com/drug' in i]\n",
        "len(U)"
      ],
      "metadata": {
        "id": "Tq5N16vPxP0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(set(U)))"
      ],
      "metadata": {
        "id": "T9B_sH3dxX6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U = list(set(U))\n",
        "U"
      ],
      "metadata": {
        "id": "DV4igwMtxbP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(U)"
      ],
      "metadata": {
        "id": "-CMNgKjWxgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U[0]"
      ],
      "metadata": {
        "id": "gqS_pHUPxiT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm  import tqdm"
      ],
      "metadata": {
        "id": "r4kASepoxlHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AllData = {}\n",
        "for u in tqdm(U[:5]) :\n",
        "  website = requests.get(u)\n",
        "  Divs = ['whatisdrug','method','frequency','dosagerange','affectiontime','affectionperiod',\"nutrition\",\"storage\",\"forgotenmeal\",\n",
        "          \"medecinestop\",\"excessdosing\",\"pregnancy\",\"breastfeed\",\"children\",\"olds\",\"driving\",\"surgery\",\"sideeffects\",\"commercialnames\"]\n",
        "  A = {}\n",
        "  for Key in Divs :\n",
        "    soup = BeautifulSoup(website.content)\n",
        "    L = [''.join(s.find_all(text=True)) for s in soup.findAll(\"div\", {\"id\": Key})]\n",
        "    if len(L) > 0 :\n",
        "      A[Key] =  L[0]\n",
        "    else :\n",
        "      A[Key] =  ''\n",
        "  AllData[u] = A"
      ],
      "metadata": {
        "id": "vJWL8Exwxmif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CleanedData = {i.split(r'/')[-1]:j for i,j in AllData.items()}\n",
        "CleanedData.keys()"
      ],
      "metadata": {
        "id": "lObVQFvYxp4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(CleanedData)"
      ],
      "metadata": {
        "id": "rTWB-zDIxvq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(CleanedData).T"
      ],
      "metadata": {
        "id": "u2PGziJ-yC32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(CleanedData).T.to_excel('data.xlsx')"
      ],
      "metadata": {
        "id": "eDcpPyTyyDjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Get(Name) :\n",
        "    url = r'https://www.webteb.com/drug/' + Name\n",
        "    website = requests.get(url)\n",
        "    soup = BeautifulSoup(website.content)\n",
        "    text = [''.join(s.findAll(text=True))for s in soup.findAll('p')]\n",
        "    for item in text:\n",
        "        print(item)\n",
        "\n",
        "Get('الاسبرين')"
      ],
      "metadata": {
        "id": "uk8pfIcTyLUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "url = \"https://www.webteb.com/drug/ايبوبروفين\"\n",
        "\n",
        "website = requests.get(url)\n",
        "soup = BeautifulSoup(website.content)"
      ],
      "metadata": {
        "id": "2BOmCPVdyL7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [''.join(s.findAll(text=True))for s in soup.findAll('div')]\n",
        "for item in text:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "dEjRCuadyOGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [''.join(s.findAll(text=True))for s in soup.findAll('p')]\n",
        "for item in text:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "gDcdI5CNyT5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOQMGY-jyUj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}